---
title: "online-news-popularity"
author: "Sneh Gurdasani, Akshit Jain, Farhan Ansari, Sagar Singh"
date: "11/11/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(ggcorrplot)
library(dbscan)
```

## Load and Tidy Dataset
```{r f1, echo = FALSE}
get_tidy_data <- function(df) {
  # extracting date and title from url string
  clustering_df <- df %>% 
    mutate(date = as.Date(sub(".*?\\b(\\d{4}/\\d{1,2}/\\d{1,2})\\b.*", "\\1", url)),
           article_title = word(url, -2, sep = '/'))
  
  # gather article categories and weekdays
  classification_df <- clustering_df %>% gather(key='category', value='is_category',
                            data_channel_is_lifestyle, data_channel_is_entertainment,
                            data_channel_is_bus, data_channel_is_socmed, data_channel_is_tech,
                            data_channel_is_world) %>%
    filter(is_category == 1) %>%
    select(-is_category) %>%
    mutate(category = case_when(category == 'data_channel_is_lifestyle' ~ 'Lifestyle',
                                category == 'data_channel_is_entertainment' ~ 'Entertainment',
                                category == 'data_channel_is_bus' ~ 'Business',
                                category == 'data_channel_is_socmed' ~ 'Social Media',
                                category == 'data_channel_is_tech' ~ 'Technology',
                                category == 'data_channel_is_world' ~ 'World')) %>%
    gather(key='day', value='what_day',
           weekday_is_monday, weekday_is_tuesday,
                            weekday_is_wednesday, weekday_is_thursday, weekday_is_friday,
                            weekday_is_saturday, weekday_is_sunday) %>%
    filter(what_day == 1) %>%
    select(-what_day) %>%
    mutate(day = case_when(day == 'weekday_is_monday' ~ 'Monday',
                                day == 'weekday_is_tuesday' ~ 'Tuesday',
                                day == 'weekday_is_wednesday' ~ 'Wednesday',
                                day == 'weekday_is_thursday' ~ 'Thursday',
                                day == 'weekday_is_friday' ~ 'Friday',
                                day == 'weekday_is_saturday' ~ 'Saturday',
                                day == 'weekday_is_sunday' ~ 'Sunday'))
  
  cluster_numeric_df <- clustering_df %>% 
    semi_join(classification_df, by='url') %>%
    select(-url,-article_title,-date,-timedelta,-is_weekend)
  cluster_numeric_df
  
  return(list(cluster_numeric_df, classification_df))
}
```

```{r}
df <- read_csv('OnlineNewsPopularity/OnlineNewsPopularity.csv', col_types = cols())
list_of_dfs <- get_tidy_data(df)
cluster_numeric_df <- list_of_dfs[[1]]
classification_df <- list_of_dfs[[2]]
```

```{r f2, echo = FALSE}
visualize_summary_plots <- function(df) {
  #Plot 1: Count of each day of news
  plt_day_count <- ggplot(df, aes(x = day)) + 
    geom_bar()
  print(plt_day_count)

  #Plot 2: Number of shares of each day of the weeek
  plt_day_share <- ggplot(df, aes(x = day, y = shares)) + 
    geom_bar(stat = "identity")  
  print(plt_day_share)

  #Plot 3: Average shares of news by day
  plt_avg_shares_by_day <- df %>%
    group_by(day) %>%
    summarise(count = n(), tot_share = sum(shares), avg_share = tot_share/count) %>%
    ggplot(aes(x = day, y = avg_share)) + 
    geom_bar(stat = "identity")
  print(plt_avg_shares_by_day)

  #Plot 4: Average shares of news by category each day
  plt_avg_daily_shares_by_category <- df %>%
   group_by(category, day) %>%
    summarise(count = n(), tot_share = sum(shares), avg_share = tot_share/count) %>%
    ggplot(aes(x = day, y = avg_share, fill = day)) +
    geom_bar(stat = "identity", position = "dodge") +
    theme(axis.title.x=element_blank(),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank()) +
    facet_wrap(~category)
  print(plt_avg_daily_shares_by_category)
  
  #Plot 5: Count of shares w.r.t images
  plt_img_shares <- ggplot(df, aes(x = num_imgs, y = shares)) + 
    geom_point()
  print(plt_img_shares)

  #Plot 6: Count of shares w.r.t images for each category
  plt_category_img_shares <- ggplot(df, aes(x = num_imgs, y = shares, color = category)) + 
    geom_point(alpha=1/10) +
    geom_smooth() +
    coord_cartesian(ylim = c(0,35000))
  print(plt_category_img_shares)

  #Plot 7: Count for shares w.r.t videos
  plt_videos_shares <- ggplot(df, aes(x = num_videos, y = shares)) + 
    geom_point()
  print(plt_videos_shares)

  #Plot 8: Count of shares w.r.t videos for each category
  plt_category_videos_shares <- ggplot(df, aes(x = num_videos, y = shares, color = category)) + 
    geom_point(alpha=1/10, na.rm = TRUE) + 
    geom_smooth() +
    coord_cartesian(ylim = c(-80000,130000))
  print(plt_category_videos_shares)

  #Plot 9: Global Sentiment Polarity w.r.t shares for each category 
  plt_gsp_shares_category <- ggplot(df, aes(x = global_sentiment_polarity, y = shares, color = category)) + 
    geom_point(alpha=1/2, na.rm = TRUE) +
    facet_wrap(~category)
  print(plt_gsp_shares_category)
  
  #Plot 10: Rate Positive Polarity w.r.t shares for each category 
  plt_rpp_shares_category <- ggplot(df, aes(x = rate_positive_words, y = shares, color = category)) + 
    geom_point(alpha=1/2, na.rm = TRUE) +
    facet_wrap(~category)
  print(plt_rpp_shares_category)
  
  #Plot 11: minimum negative polarity w.r.t shares for each category 
  plt_mnp_shares_category <- ggplot(df, aes(x = min_negative_polarity, y = shares, color = category)) + 
    geom_point(alpha=1/2, na.rm = TRUE) +
    facet_wrap(~category)
  print(plt_mnp_shares_category)
  
  #Plot 12: Global Rate Negative words w.r.t shares for each category 
  plt_grnw_shares_category <- ggplot(df, aes(x = global_rate_negative_words, y = shares, color = category)) + 
    geom_point(alpha=1/2, na.rm = TRUE)
  print(plt_grnw_shares_category)
  
  #Plot 13: number of token content w.r.t shares 
  plt_n_tokens_content_shares <- ggplot(df, aes(x = n_tokens_content, y = shares)) + 
    geom_histogram(alpha=1/2, na.rm = TRUE, stat = "identity") +
    coord_cartesian(ylim = c(0,300000))
  print(plt_n_tokens_content_shares)
  
  #Plot 14: global subjectivity w.r.t shares 
  plt_global_sub_shares <- ggplot(df, aes(x = global_subjectivity, y = shares)) + 
    geom_point(na.rm = TRUE)
  print(plt_global_sub_shares)
  
  #Plot 15: average token length w.r.t shares 
  plt_avg_token_length_shares <- ggplot(df, aes(x = average_token_length, y = shares)) + 
    geom_point(na.rm = TRUE)
  print(plt_avg_token_length_shares)
  
  #Plot 16: number of keywords w.r.t shares 
  plt_num_key_shares_category <- ggplot(df, aes(x = as.factor(num_keywords), 
                                                y = shares, fill = category)) + 
    geom_bar(stat = "identity") +
    facet_wrap(~category)
  print(plt_num_key_shares_category)
  
  #Plot 17: number of hrefs w.r.t shares 
  plt_num_href_shares <- ggplot(df, aes(x = num_hrefs, y = shares)) + 
    geom_histogram(na.rm = TRUE, stat = 'identity')
  print(plt_num_href_shares)
  
  #Plot 18: kw_avg_avg w.r.t shares 
  plt <- ggplot(df, aes(x = kw_avg_avg, y = shares)) + 
    geom_point(na.rm = TRUE)
  print(plt)

} 
```

```{r}
visualize_summary_plots(classification_df)
```


```{r f3, echo = FALSE}
correlation_matrix <- function(df) {
  df <- df %>% filter(category == typeOfArticle)
  corr_df <- as.data.frame(cor(df, method = c("pearson", "kendall", "spearman")))
  rownames(corr_df) <- colnames(corr_df)
  corr_df <- rownames_to_column(corr_df, var='correlation_with')
  # get top 15 variables that have correlation with 'shares'
  corr_df %>% select(correlation_with, shares) %>% top_n(15) %>% arrange(desc(shares))
}
```

```{r}
correlation_matrix(cluster_numeric_df) 
```


```{r f4, echo=FALSE}
#Principle Component Analysis for dimensionality reduction

featureSelection <- function(df,maxComponents){
  
  prcompResult <- prcomp(cluster_numeric_df,rank.= maxComponents, scale.=TRUE)
  pca_statistics <- summary(prcompResult)
  max_variance = pca_statistics[[6]][[maxComponents*3]]
  PCA_results <- as_tibble(prcompResult[[2]])
  features = rownames(prcompResult[[2]])
  PCA_results <- cbind(features,PCA_results)
  fviz_eig(prcompResult)
  print(paste0("Maximum Variance explained : ",max_variance*100," %"))
  return(PCA_results)
               
} 
```

```{r}
pca_analysis <- featureSelection(cluster_numeric_df,25)
pca_analysis 

top_features = c()

```

```{r f5, echo=FALSE}

#Clustering Algorithms

set.seed(20)

elbowPlot <- function(df,max_iter){
  wss <- data.frame(i = integer(), error = numeric())
  for (i in 2:max_iter){
    km1 <- kmeans(df, centers = i)
    wss <- rbind(wss, data.frame(i,error=sum(km1$withinss)))
  }
  g <- ggplot(data=wss, aes(x=i, y = error))+
    geom_line() + 
    geom_smooth() +
    scale_x_continuous(breaks = c(1:max_iter))
  print(g)
  return(wss)
}

apply_KMEANS = function(df,k){
  
  dfCluster <- kmeans(df, k, nstart = 20)
  print(fviz_cluster(dfCluster, df,  geom = "point"))
  
  return(dfCluster) 
}


apply_DBScan = function(df,e,p){
  
  res.db <- dbscan::dbscan(scale(df),  eps= e, minPts =p)
  fviz_cluster(res.db, scale(df),  geom = "point")
  return(res.db)
}


```

```{r f6, echo=FALSE}
#Clustering Analysis: Exploration Phase



#kNNdistplot(scale(test), k=5)



```


```{r f7, echo = FALSE}
prepare_data_classification <- function(df) {
  print(summary(df$shares))
  # trying to categorize articles based on the mean shares -> NOT A GOOD IDEA!
  # gives a highly unbalanced label distribution
  # need to come up with a better methodology for classification.
  cl_df <- df %>% mutate(is_popular = if_else(shares > 2929, 'Popular', 'Unpopular'))
  cl_df %>% group_by(is_popular) %>% summarise(n())
}
```

```{r}
prepare_data_classification(classification_df)
```

